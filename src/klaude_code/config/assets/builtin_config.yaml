# Built-in provider and model configurations
# Users can start using klaude by simply setting environment variables
# (ANTHROPIC_API_KEY, OPENAI_API_KEY, etc.) without manual configuration.
provider_list:
- provider_name: anthropic
  protocol: anthropic
  api_key: ${ANTHROPIC_API_KEY}
  model_list:

  - model_name: sonnet
    model_id: claude-sonnet-4-6
    context_limit: 200000
    thinking:
      type: adaptive
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

  - model_name: sonnet-no-thinking
    model_id: claude-sonnet-4-6
    context_limit: 200000
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

  - model_name: opus
    model_id: claude-opus-4-6
    context_limit: 200000
    verbosity: high
    thinking:
      type: adaptive
    cost: { input: 5, output: 25, cache_read: 0.5, cache_write: 6.25 }

- provider_name: openai
  protocol: responses
  api_key: ${OPENAI_API_KEY}
  model_list:

  - model_name: gpt-5.2-high
    model_id: gpt-5.2
    max_tokens: 128000
    context_limit: 400000
    verbosity: high
    thinking:
      reasoning_effort: high
      reasoning_summary: concise
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

  - model_name: gpt-5.3-codex
    model_id: gpt-5.3-codex
    thinking:
      reasoning_effort: high
      reasoning_summary: auto
    context_limit: 400000
    max_tokens: 128000
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

  - model_name: gpt-5.3-codex-xhigh
    model_id: gpt-5.3-codex
    thinking:
      reasoning_effort: xhigh
      reasoning_summary: auto
    context_limit: 400000
    max_tokens: 128000
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

- provider_name: openrouter
  protocol: openrouter
  api_key: ${OPENROUTER_API_KEY}
  model_list:

  - model_name: gpt-5.3-codex
    model_id: openai/gpt-5.3-codex
    thinking:
      reasoning_effort: high
      reasoning_summary: auto
    context_limit: 400000
    max_tokens: 128000
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

  - model_name: gpt-5.3-codex-xhigh
    model_id: openai/gpt-5.3-codex
    thinking:
      reasoning_effort: xhigh
      reasoning_summary: auto
    context_limit: 400000
    max_tokens: 128000
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

  - model_name: gpt-5.2-high
    model_id: openai/gpt-5.2
    max_tokens: 128000
    context_limit: 400000
    verbosity: high
    thinking:
      reasoning_effort: high
      reasoning_summary: concise
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

  - model_name: kimi
    model_id: moonshotai/kimi-k2.5
    context_limit: 262144
    provider_routing:
      only:
      - fireworks
      - moonshotai/int4
      - novita
    cost: { input: 0.6, output: 3, cache_read: 0.1 }

  - model_name: kimi-no-thinking
    model_id: moonshotai/kimi-k2.5
    context_limit: 262144
    provider_routing:
      only:
      - fireworks
      - moonshotai/int4
      - novita
    cost: { input: 0.6, output: 3, cache_read: 0.1 }

  - model_name: qwen
    model_id: qwen/qwen3-coder-next
    context_limit: 262144
    cost: { input: 0.2, output: 1.5 }

  - model_name: qwen-3.5-plus
    model_id: qwen/qwen3.5-plus-02-15
    context_limit: 1000000
    cost: { input: 0.4, output: 2.4 }

  - model_name: haiku
    model_id: anthropic/claude-haiku-4.5
    context_limit: 200000
    cost: { input: 1, output: 5, cache_read: 0.1, cache_write: 1.25 }

  - model_name: sonnet
    model_id: anthropic/claude-sonnet-4.6
    context_limit: 200000
    provider_routing:
      sort: throughput
    thinking:
      type: adaptive
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

  - model_name: sonnet-no-thinking
    model_id: anthropic/claude-sonnet-4.6
    context_limit: 200000
    provider_routing:
      sort: throughput
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

  - model_name: opus
    model_id: anthropic/claude-opus-4.6
    context_limit: 200000
    verbosity: high
    thinking:
      type: adaptive
    cost: { input: 5, output: 25, cache_read: 0.5, cache_write: 6.25 }

  - model_name: gemini-pro
    model_id: google/gemini-3.1-pro-preview
    context_limit: 1048576
    thinking:
      reasoning_effort: high
    cost: { input: 2, output: 12, cache_read: 0.2 }

  - model_name: gemini-flash
    model_id: google/gemini-3-flash-preview
    context_limit: 1048576
    thinking:
      reasoning_effort: medium
    cost: { input: 0.5, output: 3, cache_read: 0.05 }

  - model_name: grok
    model_id: x-ai/grok-4.1-fast
    context_limit: 2000000
    thinking:
      type: enabled
      budget_tokens: 2048
    cost: { input: 0.2, output: 0.5, cache_read: 0.05 }

  - model_name: minimax
    model_id: minimax/minimax-m2.5
    context_limit: 204800
    thinking:
      type: enabled
      budget_tokens: 2048
    provider_routing:
      only:
      - minimax/highspeed
    cost: { input: 0.3, output: 1.2, cache_read: 0.03 }

  - model_name: glm
    model_id: z-ai/glm-5
    context_limit: 202752
    provider_routing:
      only:
      - fireworks
      - z-ai
    cost: { input: 1, output: 3.2, cache_read: 0.1 }

- provider_name: google
  protocol: google
  api_key: ${GOOGLE_API_KEY}
  model_list:

  - model_name: gemini-pro
    model_id: gemini-3.1-pro-preview
    context_limit: 1048576
    thinking:
      reasoning_effort: high
    cost: { input: 2, output: 12, cache_read: 0.2 }

  - model_name: gemini-flash
    model_id: gemini-3-flash-preview
    context_limit: 1048576
    thinking:
      reasoning_effort: medium
    cost: { input: 0.5, output: 3, cache_read: 0.05 }

- provider_name: google-vertex
  protocol: google_vertex
  google_application_credentials: ${GOOGLE_APPLICATION_CREDENTIALS}
  google_cloud_project: ${GOOGLE_CLOUD_PROJECT}
  google_cloud_location: ${GOOGLE_CLOUD_LOCATION}
  model_list:

  - model_name: gemini-pro
    model_id: gemini-3.1-pro-preview
    context_limit: 1048576
    thinking:
      reasoning_effort: high
    cost: { input: 2, output: 12, cache_read: 0.2 }

  - model_name: gemini-flash
    model_id: gemini-3-flash-preview
    context_limit: 1048576
    thinking:
      reasoning_effort: medium
    cost: { input: 0.5, output: 3, cache_read: 0.05 }

- provider_name: bedrock
  protocol: bedrock
  aws_access_key: ${AWS_ACCESS_KEY_ID}
  aws_secret_key: ${AWS_SECRET_ACCESS_KEY}
  aws_region: ${AWS_REGION}
  model_list:

  - model_name: sonnet
    model_id: anthropic.claude-sonnet-4-6
    context_limit: 200000
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

- provider_name: deepseek
  protocol: anthropic
  api_key: ${DEEPSEEK_API_KEY}
  base_url: https://api.deepseek.com/anthropic
  model_list:

  - model_name: deepseek
    model_id: deepseek-reasoner
    context_limit: 128000
    thinking:
      type: enabled
      budget_tokens: 2048
    cost: { input: 2, output: 3, cache_read: 0.2, currency: CNY }

- provider_name: moonshot
  protocol: anthropic
  api_key: ${MOONSHOT_API_KEY}
  base_url: https://api.moonshot.cn/anthropic
  model_list:

  - model_name: kimi
    model_id: kimi-k2.5
    context_limit: 262144
    thinking:
      type: enabled
      budget_tokens: 8192
    cost: { input: 4, output: 21, cache_read: 0.7, currency: CNY }

  - model_name: kimi-no-thinking
    model_id: kimi-k2.5
    context_limit: 262144
    cost: { input: 4, output: 21, cache_read: 0.7, currency: CNY }

- provider_name: opencode-zen
  protocol: openai
  api_key: ${OPENCODE_API_KEY}
  base_url: https://opencode.ai/zen/v1
  model_list:

  - model_name: minimax
    model_id: minimax-m2.5-free
    context_limit: 204800
    thinking:
      type: enabled
      budget_tokens: 2048
    cost: { input: 0, output: 0 }

  - model_name: kimi
    model_id: kimi-k2.5-free
    context_limit: 262144
    cost: { input: 0, output: 0 }

- provider_name: cerebras
  protocol: openai
  api_key: ${CEREBRAS_API_KEY}
  base_url: https://api.cerebras.ai/v1
  model_list:

  - model_name: glm
    model_id: zai-glm-4.7
    context_limit: 131072
    max_tokens: 12800
    cost: { input: 2.25, output: 2.75 }

- provider_name: claude-max
  protocol: claude_oauth
  disabled: true
  model_list:

  - model_name: sonnet
    model_id: claude-sonnet-4-6
    context_limit: 200000
    thinking:
      type: adaptive
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

  - model_name: sonnet-no-thinking
    model_id: claude-sonnet-4-6
    context_limit: 200000
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

  - model_name: opus
    model_id: claude-opus-4-6
    context_limit: 200000
    verbosity: high
    thinking:
      type: adaptive
    cost: { input: 5, output: 25, cache_read: 0.5, cache_write: 6.25 }

  - model_name: haiku
    model_id: claude-haiku-4-5-20251001
    context_limit: 200000
    cost: { input: 1, output: 5, cache_read: 0.1, cache_write: 1.25 }

- provider_name: codex
  protocol: codex_oauth
  model_list:

  - model_name: gpt-5.3-codex
    model_id: gpt-5.3-codex
    thinking:
      reasoning_effort: high
      reasoning_summary: auto
    context_limit: 400000
    max_tokens: 128000
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

  - model_name: gpt-5.3-codex-xhigh
    model_id: gpt-5.3-codex
    thinking:
      reasoning_effort: xhigh
      reasoning_summary: auto
    context_limit: 400000
    max_tokens: 128000
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

- provider_name: copilot
  protocol: copilot_oauth
  model_list:

  - model_name: gpt-5.3-codex
    model_id: gpt-5.3-codex
    thinking:
      reasoning_effort: high
      reasoning_summary: auto
    context_limit: 400000
    max_tokens: 128000
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

  - model_name: gpt-5.3-codex-xhigh
    model_id: gpt-5.3-codex
    thinking:
      reasoning_effort: xhigh
      reasoning_summary: auto
    context_limit: 400000
    max_tokens: 128000
    cost: { input: 1.75, output: 14, cache_read: 0.17 }

  - model_name: sonnet
    model_id: claude-sonnet-4-6
    context_limit: 200000
    thinking:
      type: adaptive
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

  - model_name: sonnet-4.5
    model_id: claude-sonnet-4-5
    context_limit: 200000
    thinking:
      type: enabled
      budget_tokens: 2048
    cost: { input: 3, output: 15, cache_read: 0.3, cache_write: 3.75 }

  - model_name: haiku
    model_id: claude-haiku-4-5
    context_limit: 200000
    thinking:
      type: enabled
      budget_tokens: 2048
    cost: { input: 1, output: 5, cache_read: 0.1, cache_write: 1.25 }

  - model_name: opus
    model_id: claude-opus-4-6
    context_limit: 200000
    verbosity: high
    thinking:
      type: adaptive
    cost: { input: 5, output: 25, cache_read: 0.5, cache_write: 6.25 }

- provider_name: ark-api
  protocol: responses
  api_key: ${ARK_API_KEY}
  base_url: https://ark.cn-beijing.volces.com/api/v3
  model_list:

  - model_name: seed-pro
    model_id: doubao-seed-2-0-pro-260215
    context_limit: 256000
    thinking:
      type: enabled
      budget_tokens: 8192
    cost: { input: 4.8, output: 24, cache_read: 0.96, currency: CNY }

  - model_name: seed-code
    model_id: doubao-seed-2-0-code-preview-260215
    context_limit: 256000
    thinking:
      type: enabled
      budget_tokens: 8192
    cost: { input: 4.8, output: 24, cache_read: 0.96, currency: CNY }

- provider_name: ark-coding-plan
  protocol: anthropic
  api_key: ${ARK_API_KEY}
  base_url: https://ark.cn-beijing.volces.com/api/coding/
  model_list:

  - model_name: seed-code
    model_id: doubao-seed-2.0-code
    context_limit: 256000
    cost: { input: 4.8, output: 24, cache_read: 0.96, currency: CNY }
    thinking:
      type: enabled
      budget_tokens: 8192

  - model_name: kimi
    model_id: kimi-k2.5
    context_limit: 262144
    cost: { input: 4, output: 21, cache_read: 0.7, currency: CNY }
    thinking:
      type: enabled
      budget_tokens: 8192

compact_model: gemini-flash

sub_agent_models:
  Explore: sonnet-no-thinking
